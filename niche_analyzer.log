2025-04-14 14:02:42,821 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.250.228:8000
2025-04-14 14:02:42,821 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 14:02:51,848 - ERROR - 192.168.250.228 - - [14/Apr/2025 14:02:51] code 400, message Bad request version ('CµãË±t+K')
2025-04-14 14:02:51,848 - INFO - 192.168.250.228 - - [14/Apr/2025 14:02:51] "[31m[1m\x16\x03\x01\x06 \x01\x00\x06\x9c\x03\x03÷:ÖO®\x92:+\x0b¼Ô\x1d\x08\x92S\x9dúó\x9aMÜvìçA\x89\x04\x09\x17Ó°L \x16Ð×xRbViW\x82\x00\x90\x1f\x80Z4hÓ£Õ\x19ýCò#\x0e¸Â\x96ö`T\x00 ºº\x13\x01\x13\x02\x13\x03À+À/À,À0Ì©Ì¨À\x13À\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x063jj\x00\x00\x00\x0b\x00\x02\x01\x00\x00+\x00\x07\x06\x9a\x9a\x03\x04\x03\x03\x00#\x00\x00\x00\x12\x00\x00þ\x0d\x00º\x00\x00\x01\x00\x01R\x00 Ù];\x0b¤n\x18\x19\x9b\x07ß\x86îú\x95Õ]\x19Í\x9a$Ü\\Ìv\x9e*¬2²n$\x00\x90ÒI®ît<e®\x14gfF=\x98\x8f\x93³Y}¿\x12&ÎFo³\x00\x1fñ\x1fU|Öt=\x97álJ®\x11J¥.Û\x021ê\x0fôyox\x08äl Õ\x1cls©À\x82ä\x8d\x8b0\x17\x90°óÏ¨G2\x04\x91Æ¾\\\x19\x89Vàô\x1f\x15\x9elñTm?\x0b>%Ø\x99Ä8È³vézØ\x0f}\x85\x02i\x1e\x01\x07ãÞ¡\x0cY\x08XCö\x86_÷8\x95PÛ\x94YÂ\x98×bÁ\x83·À¼\\Ô\x00-\x00\x02\x01\x01\x00\x17\x00\x00ÿ\x01\x00\x01\x00Di\x00\x05\x00\x03\x02h2\x00\x1b\x00\x03\x02\x00\x02\x003\x04ï\x04íJJ\x00\x01\x00\x11ì\x04À¿{\x0b-Á\x03³ì\x0dÈ\x99xg\x85\x92\x82\x83,9£Ã\x9f¡f@\x18¯\x02P\x04ÖL\x0dç CµãË±t+K[0m" 400 -
2025-04-14 14:02:51,854 - ERROR - 192.168.250.228 - - [14/Apr/2025 14:02:51] code 400, message Bad request version ('tm\x80\x1b\\zÀóè\x8bQ¶H\x14')
2025-04-14 14:02:51,856 - INFO - 192.168.250.228 - - [14/Apr/2025 14:02:51] "[31m[1m\x16\x03\x01\x07\x00\x01\x00\x06ü\x03\x03ú+P±>\x1b\x1dbzs7®æ[Wÿ\x06'¨\x07\x81ëGt¬O\x10"ÓL\x8eÅ «î5ÇÜUïü\x93ÃÂ\x0dÙÔèwE\x80På$I$\x7f\x19úíÄ±>\x9fq\x00 \x8a\x8a\x13\x01\x13\x02\x13\x03À+À/À,À0Ì©Ì¨À\x13À\x14\x00\x9c\x00\x9d\x00/\x005\x01\x00\x06\x93zz\x00\x00\x003\x04ï\x04ízz\x00\x01\x00\x11ì\x04À¥WÁÿ\x82³\x8fÈ\x9e.à«sô\x1aFs,¦h\x18¥ù5«Ë\x0fàÖ\x97`·S\x1aÉ\x1d/éjäÚ\x99\x05èµ\x07õ\x17³{\x97ì\x09tm\x80\x1b\\zÀóè\x8bQ¶H\x14[0m" 400 -
2025-04-14 14:03:00,404 - INFO - 192.168.250.228 - - [14/Apr/2025 14:03:00] "[33mGET / HTTP/1.1[0m" 404 -
2025-04-14 14:03:01,725 - INFO - 192.168.250.228 - - [14/Apr/2025 14:03:01] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-04-14 14:17:46,612 - INFO - 192.168.250.228 - - [14/Apr/2025 14:17:46] "[33mGET / HTTP/1.1[0m" 404 -
2025-04-14 14:23:03,064 - INFO - 127.0.0.1 - - [14/Apr/2025 14:23:03] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:23:03,095 - INFO - Starting analysis for: healthcare
2025-04-14 14:23:03,097 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\share\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 14:23:16,814 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 14:23:16,814 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 14:23:17,853 - INFO - Found 0 DuckDuckGo results for 'challenges facing healthcare businesses'
2025-04-14 14:23:17,853 - WARNING - No data collected from scraping
2025-04-14 14:23:17,858 - INFO - 127.0.0.1 - - [14/Apr/2025 14:23:17] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:23:32,631 - INFO - 127.0.0.1 - - [14/Apr/2025 14:23:32] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:23:32,646 - INFO - Starting analysis for: healthcare
2025-04-14 14:23:32,650 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\share\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 14:23:41,352 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 14:23:41,360 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 14:23:44,250 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 14:23:44,250 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 14:23:44,260 - WARNING - No data collected from scraping
2025-04-14 14:23:44,262 - INFO - 127.0.0.1 - - [14/Apr/2025 14:23:44] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:25:02,140 - INFO - 127.0.0.1 - - [14/Apr/2025 14:25:02] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:25:02,157 - INFO - Starting analysis for: healthcare
2025-04-14 14:25:03,647 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 14:25:03,647 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 14:25:03,926 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 14:25:03,926 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 14:25:03,926 - WARNING - No data collected from scraping
2025-04-14 14:25:03,926 - INFO - 127.0.0.1 - - [14/Apr/2025 14:25:03] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:35:40,119 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.250.228:8000
2025-04-14 14:35:40,119 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 14:56:03,026 - INFO - 127.0.0.1 - - [14/Apr/2025 14:56:03] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 14:56:03,041 - INFO - Starting analysis for: Health & Wellness
2025-04-14 14:56:03,044 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\share\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 14:56:12,170 - WARNING - Error fetching https://html.duckduckgo.com/html/ (attempt 1): Cannot connect to host html.duckduckgo.com:443 ssl:default [The specified network name is no longer available]
2025-04-14 14:56:18,401 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 14:56:18,401 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 14:56:23,051 - WARNING - Scraping task failed: 
2025-04-14 14:56:23,051 - WARNING - No data collected from scraping
2025-04-14 14:56:23,051 - INFO - 127.0.0.1 - - [14/Apr/2025 14:56:23] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:06:36,472 - INFO - 127.0.0.1 - - [14/Apr/2025 15:06:36] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:06:36,477 - INFO - Starting analysis for: Health & Wellness
2025-04-14 15:06:36,479 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\share\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Local\\Programs\\Python\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 15:06:47,794 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 15:06:47,794 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 15:06:47,996 - INFO - Found 0 DuckDuckGo results for ' in Health & Wellness sector'
2025-04-14 15:06:47,996 - WARNING - No data collected from scraping
2025-04-14 15:06:47,996 - INFO - 127.0.0.1 - - [14/Apr/2025 15:06:47] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:28:26,256 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.250.228:8000
2025-04-14 15:28:26,256 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 15:28:59,086 - INFO - 127.0.0.1 - - [14/Apr/2025 15:28:59] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:28:59,086 - ERROR - Exception on /analyze/niche [POST]
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_limiter\extension.py", line 1314, in __inner
    return cast(R, flask.current_app.ensure_sync(obj)(*a, **k))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 976, in ensure_sync
    return self.async_to_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 997, in async_to_sync
    raise RuntimeError(
RuntimeError: Install Flask with the 'async' extra in order to use async views.
2025-04-14 15:28:59,086 - ERROR - Server error: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-04-14 15:28:59,086 - INFO - 127.0.0.1 - - [14/Apr/2025 15:28:59] "[35m[1mPOST /analyze/niche HTTP/1.1[0m" 500 -
2025-04-14 15:29:01,113 - ERROR - Exception on /analyze/niche [POST]
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_limiter\extension.py", line 1314, in __inner
    return cast(R, flask.current_app.ensure_sync(obj)(*a, **k))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 976, in ensure_sync
    return self.async_to_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 997, in async_to_sync
    raise RuntimeError(
RuntimeError: Install Flask with the 'async' extra in order to use async views.
2025-04-14 15:29:01,117 - ERROR - Server error: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-04-14 15:29:01,118 - INFO - 127.0.0.1 - - [14/Apr/2025 15:29:01] "[35m[1mPOST /analyze/niche HTTP/1.1[0m" 500 -
2025-04-14 15:30:50,848 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.250.228:8000
2025-04-14 15:30:50,848 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 15:30:55,422 - INFO - 127.0.0.1 - - [14/Apr/2025 15:30:55] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:30:55,425 - ERROR - Exception on /analyze/niche [POST]
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_limiter\extension.py", line 1314, in __inner
    return cast(R, flask.current_app.ensure_sync(obj)(*a, **k))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 976, in ensure_sync
    return self.async_to_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 997, in async_to_sync
    raise RuntimeError(
RuntimeError: Install Flask with the 'async' extra in order to use async views.
2025-04-14 15:30:55,427 - ERROR - Server error: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-04-14 15:30:55,427 - INFO - 127.0.0.1 - - [14/Apr/2025 15:30:55] "[35m[1mPOST /analyze/niche HTTP/1.1[0m" 500 -
2025-04-14 15:30:56,336 - ERROR - Exception on /analyze/niche [POST]
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_limiter\extension.py", line 1314, in __inner
    return cast(R, flask.current_app.ensure_sync(obj)(*a, **k))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 976, in ensure_sync
    return self.async_to_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 997, in async_to_sync
    raise RuntimeError(
RuntimeError: Install Flask with the 'async' extra in order to use async views.
2025-04-14 15:30:56,336 - ERROR - Server error: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-04-14 15:30:56,336 - INFO - 127.0.0.1 - - [14/Apr/2025 15:30:56] "[35m[1mPOST /analyze/niche HTTP/1.1[0m" 500 -
2025-04-14 15:30:56,922 - ERROR - Exception on /analyze/niche [POST]
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask_limiter\extension.py", line 1314, in __inner
    return cast(R, flask.current_app.ensure_sync(obj)(*a, **k))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 976, in ensure_sync
    return self.async_to_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\flask\app.py", line 997, in async_to_sync
    raise RuntimeError(
RuntimeError: Install Flask with the 'async' extra in order to use async views.
2025-04-14 15:30:56,925 - ERROR - Server error: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.
2025-04-14 15:30:56,925 - INFO - 127.0.0.1 - - [14/Apr/2025 15:30:56] "[35m[1mPOST /analyze/niche HTTP/1.1[0m" 500 -
2025-04-14 15:33:25,157 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.250.228:8000
2025-04-14 15:33:25,157 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 15:33:30,606 - INFO - 127.0.0.1 - - [14/Apr/2025 15:33:30] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:33:30,619 - INFO - Starting analysis for: Health & Wellness
2025-04-14 15:33:30,619 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 15:33:32,625 - ERROR - Client error 400 fetching https://html.duckduckgo.com/html/: Can not decode content-encoding: brotli (br). Please install `Brotli`
2025-04-14 15:33:32,625 - ERROR - Failed to fetch https://html.duckduckgo.com/html/ after 3 attempts
2025-04-14 15:33:32,736 - INFO - Found 0 DuckDuckGo results for 'growth opportunities in Health & Wellness'
2025-04-14 15:33:32,736 - WARNING - No data collected from scraping
2025-04-14 15:33:32,736 - INFO - 127.0.0.1 - - [14/Apr/2025 15:33:32] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:34:53,496 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.250.228:8000
2025-04-14 15:34:53,496 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 15:35:20,967 - INFO - 127.0.0.1 - - [14/Apr/2025 15:35:20] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:35:20,977 - INFO - Starting analysis for: Health & Wellness
2025-04-14 15:35:20,981 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 15:35:22,027 - INFO - Found 5 DuckDuckGo results for 'growth opportunities in Health & Wellness'
2025-04-14 15:35:22,067 - INFO - Found 5 DuckDuckGo results for 'Health & Wellness market trends'
2025-04-14 15:35:22,072 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 15:35:22,073 - ERROR - Sentiment analysis failed: 'AIModels' object has no attribute 'sentiment_analyzer'
2025-04-14 15:35:22,073 - ERROR - Topic modeling failed: 'AIModels' object has no attribute 'topic_modeler'
2025-04-14 15:35:22,073 - ERROR - NER extraction failed: 'AIModels' object has no attribute 'ner_model'
2025-04-14 15:35:22,081 - INFO - Analysis completed in 1.10s
2025-04-14 15:35:22,088 - INFO - 127.0.0.1 - - [14/Apr/2025 15:35:22] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 15:43:42,119 - INFO - Loading NLP models...
2025-04-14 15:44:29,377 - ERROR - Error loading models: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\pipelines\base.py", line 291, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 4260, in from_pretrained
    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 1100, in _get_resolved_checkpoint_files
    raise EnvironmentError(
OSError: sshleifer/distilbart-cnn-12-6 does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\pipelines\base.py", line 291, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 4260, in from_pretrained
    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 1100, in _get_resolved_checkpoint_files
    raise EnvironmentError(
OSError: sshleifer/distilbart-cnn-12-6 does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.


Traceback (most recent call last):
  File "c:\Work\Hackathons\codefest\CodeFest\src\Backend\main.py", line 207, in load_models
    self.summarizer = pipeline(
                      ^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\pipelines\__init__.py", line 942, in pipeline
    framework, model = infer_framework_load_model(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\pipelines\base.py", line 304, in infer_framework_load_model
    raise ValueError(
ValueError: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\pipelines\base.py", line 291, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 4260, in from_pretrained
    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 1100, in _get_resolved_checkpoint_files
    raise EnvironmentError(
OSError: sshleifer/distilbart-cnn-12-6 does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\pipelines\base.py", line 291, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 4260, in from_pretrained
    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Work\Hackathons\codefest\CodeFest\venv\Lib\site-packages\transformers\modeling_utils.py", line 1100, in _get_resolved_checkpoint_files
    raise EnvironmentError(
OSError: sshleifer/distilbart-cnn-12-6 does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.



2025-04-14 15:44:29,379 - CRITICAL - Failed to initialize application: Failed to load AI models
2025-04-14 15:44:44,824 - INFO - Loading NLP models...
2025-04-14 15:46:27,873 - WARNING - Error while downloading from https://cdn-lfs.hf.co/sshleifer/distilbart-cnn-12-6/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1744629286&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDYyOTI4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9zc2hsZWlmZXIvZGlzdGlsYmFydC1jbm4tMTItNi8zYmFjNjVkMThjOTk0NjMzMDJkMTJjYTc1YzIyMjBlYTcxNGY5YzgxY2UyMzVmMjA1ZmE4MThlZmU3MWRmNmVhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=VDyNYnhp3IYc10rLPhfircYMM5Iw6Hqvqqi6x8xvoqfiiYhUcERZpHveRicaIrzrzJ%7EtK1ThGJ7XfSW4Ht1cWePKN6YEJ4%7EJ5uQNdHYEPpgh0FIAWr4SaegXdzRHmUsYyzSd%7E9cMTP97Urh7y-flOPwK%7EC2rgHA4ivvrqAc2kdSTp-I-5Uqh1ISDSHVVDGtaXLl3o2wDbrODuVSlyxSA0NSCkRA75vYO38IVMDtYoZbWvZ3e-6Jpp6261hL3M7UHO4lvzs286-BDbe1Q5RPb9BCZg4lUqEmE4ZkXWtKFvYfIvLuMSvyYu1gKJHqQtpMwHeeB7N%7EJ%7EAhScEcTr%7ErPuA__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
2025-04-14 15:49:11,753 - INFO - Loading NLP models (local only)...
2025-04-14 15:50:18,088 - WARNING - Error while downloading from https://cdn-lfs.hf.co/sshleifer/distilbart-cnn-12-6/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1744629554&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDYyOTU1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9zc2hsZWlmZXIvZGlzdGlsYmFydC1jbm4tMTItNi8zYmFjNjVkMThjOTk0NjMzMDJkMTJjYTc1YzIyMjBlYTcxNGY5YzgxY2UyMzVmMjA1ZmE4MThlZmU3MWRmNmVhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=cRFJkfSkjBLLIUE26fAJ7xBT5Jl56vdeTJ2uq0mtrWFz7UC3y0MBBdpg1E9niS7ksv2iq4VVUS%7EGTnt2%7ESzSDRVg7AZgrIclUcc6W0MXWP29-ZA-gEpb9BtXHnUbqnXv5e3YvsoyPxf34omDYujoFZF9RoNpo2LaAUA1OG4ScJaSZYJWVd8UK0zLykwVlKH6eGhxS2ZOOLF%7EGQr%7EriQhjo1XYVVoSiWh1HMt8lZwPpVtTY5XW%7EDS6d8RjwQ7rtRIEKr4%7Ey6ZUHIcdqd7qhhpl49CBFjaiuFVDEjM6fRT0%7EXLYSY4KlyTbcogruaGTDev354aNIrI7lZsuNol0bktVw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
2025-04-14 15:51:17,735 - INFO - Loading NLP models...
2025-04-14 16:03:47,788 - WARNING - Error while downloading from https://cdn-lfs.hf.co/sshleifer/distilbart-cnn-12-6/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1744629679&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDYyOTY3OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9zc2hsZWlmZXIvZGlzdGlsYmFydC1jbm4tMTItNi8zYmFjNjVkMThjOTk0NjMzMDJkMTJjYTc1YzIyMjBlYTcxNGY5YzgxY2UyMzVmMjA1ZmE4MThlZmU3MWRmNmVhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=O4sJsQuPYY-lalwxdItkOyhkI0JRkRBE7I15P6-fhr1s6pB6LQVNHVzRyYxOJj6dysy%7EE9KxsN-jTJUNlxuDJie0-0eHY3vPZfFRzxsCmgscjEKf%7E4Jc3a972q81Mka9txzdMGC1tZwAlUDEykNKQuU0iiDtze5kKmhiJA22iimMKzdxwUM0p4hQAcKrDUXXRFGlDye9w0ypWThfHO6aF6o4J4%7EsJ-dYfXg9Ozams-wkfd5QKn-poyBo-XsAG8OfWnCtXGF-7XPyajjlPeaQGknl3R1V7JUbAGZXgR57kNKg-MH7QNzTCTL-2R87a2x-daWvwd8tsyl8MUTx%7ELo%7E9A__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
2025-04-14 16:12:14,237 - WARNING - Error while downloading from https://cdn-lfs.hf.co/sshleifer/distilbart-cnn-12-6/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1744629679&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDYyOTY3OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9zc2hsZWlmZXIvZGlzdGlsYmFydC1jbm4tMTItNi8zYmFjNjVkMThjOTk0NjMzMDJkMTJjYTc1YzIyMjBlYTcxNGY5YzgxY2UyMzVmMjA1ZmE4MThlZmU3MWRmNmVhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=O4sJsQuPYY-lalwxdItkOyhkI0JRkRBE7I15P6-fhr1s6pB6LQVNHVzRyYxOJj6dysy%7EE9KxsN-jTJUNlxuDJie0-0eHY3vPZfFRzxsCmgscjEKf%7E4Jc3a972q81Mka9txzdMGC1tZwAlUDEykNKQuU0iiDtze5kKmhiJA22iimMKzdxwUM0p4hQAcKrDUXXRFGlDye9w0ypWThfHO6aF6o4J4%7EsJ-dYfXg9Ozams-wkfd5QKn-poyBo-XsAG8OfWnCtXGF-7XPyajjlPeaQGknl3R1V7JUbAGZXgR57kNKg-MH7QNzTCTL-2R87a2x-daWvwd8tsyl8MUTx%7ELo%7E9A__&Key-Pair-Id=K3RPWS32NSSJCE: The operation did not complete (read) (_ssl.c:2559)
Trying to resume download...
2025-04-14 16:17:11,450 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://172.25.188.238:8000
2025-04-14 16:17:11,450 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 16:17:40,089 - INFO - 127.0.0.1 - - [14/Apr/2025 16:17:40] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 16:17:40,097 - INFO - Starting analysis for: Health & Wellness
2025-04-14 16:17:40,101 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - './nltk_data'
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 16:17:46,009 - INFO - Found 5 DuckDuckGo results for ' in Health & Wellness sector'
2025-04-14 16:17:46,028 - INFO - Found 0 DuckDuckGo results for 'challenges facing Health & Wellness businesses'
2025-04-14 16:17:46,028 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - './nltk_data'
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 16:17:46,028 - ERROR - Sentiment analysis failed: 'AIModels' object has no attribute 'sentiment_analyzer'
2025-04-14 16:17:46,028 - ERROR - Topic modeling failed: 'AIModels' object has no attribute 'topic_modeler'
2025-04-14 16:17:46,028 - ERROR - NER extraction failed: 'AIModels' object has no attribute 'ner_model'
2025-04-14 16:17:46,028 - INFO - Analysis completed in 5.93s
2025-04-14 16:17:46,036 - INFO - 127.0.0.1 - - [14/Apr/2025 16:17:46] "POST /analyze/niche HTTP/1.1" 200 -
2025-04-14 16:22:27,930 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://172.25.188.238:8000
2025-04-14 16:22:27,930 - INFO - [33mPress CTRL+C to quit[0m
2025-04-14 16:22:55,632 - INFO - 127.0.0.1 - - [14/Apr/2025 16:22:55] "OPTIONS /analyze/niche HTTP/1.1" 200 -
2025-04-14 16:22:55,643 - INFO - Starting analysis for: Health & Wellness
2025-04-14 16:22:55,651 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - './nltk_data'
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 16:22:57,718 - INFO - Found 5 DuckDuckGo results for 'challenges facing Health & Wellness businesses'
2025-04-14 16:22:57,718 - INFO - Found 5 DuckDuckGo results for 'growth opportunities in Health & Wellness'
2025-04-14 16:22:57,723 - ERROR - Keyword extraction failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - './nltk_data'
    - 'C:\\Users\\kushagra pant/nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\share\\nltk_data'
    - 'C:\\Work\\Hackathons\\codefest\\CodeFest\\venv\\lib\\nltk_data'
    - 'C:\\Users\\kushagra pant\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - './nltk_data'
**********************************************************************

2025-04-14 16:22:57,723 - ERROR - Sentiment analysis failed: 'AIModels' object has no attribute 'sentiment_analyzer'
2025-04-14 16:22:57,723 - ERROR - Topic modeling failed: 'AIModels' object has no attribute 'topic_modeler'
2025-04-14 16:22:57,723 - ERROR - NER extraction failed: 'AIModels' object has no attribute 'ner_model'
2025-04-14 16:22:57,723 - INFO - Analysis completed in 2.08s
2025-04-14 16:22:57,723 - INFO - 127.0.0.1 - - [14/Apr/2025 16:22:57] "POST /analyze/niche HTTP/1.1" 200 -
